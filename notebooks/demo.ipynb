{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "import massspecgym.utils as utils\n",
    "from massspecgym.data import MassSpecDataset, RetrievalDataset, MassSpecDataModule\n",
    "from massspecgym.transforms import SpecTokenizer, MolFingerprinter, SpecBinner\n",
    "from massspecgym.models.retrieval import DeepSetsRetrieval, RandomRetrieval, FingerprintFFNRetrieval\n",
    "from massspecgym.models.de_novo import DummyDeNovo, RandomDeNovo, SmilesTransformer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(0)\n",
    "\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    mgf_pth = \"../data/debug/example_5_spectra.mgf\"\n",
    "    candidates_pth = \"../data/debug/example_5_spectra_candidates.json\"\n",
    "    split_pth=\"../data/debug/example_5_spectra_split.tsv\"\n",
    "else:\n",
    "    # Use default benchmark paths\n",
    "    mgf_pth = None\n",
    "    candidates_pth = None\n",
    "    split_pth = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Sets model on the fingerprint retrieval task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535a0ca31848444082fa93acb150333d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MassSpecGym.tsv:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anton/dev/ms/MassSpecGym/massspecgym/data/datasets.py:46: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.metadata = pd.read_csv(self.pth, sep=\"\\t\")\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/anton/miniconda3/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "# Uncomment the paths to use debugging data containing only 5 spectra\n",
    "dataset = RetrievalDataset(\n",
    "    mgf_pth=mgf_pth,\n",
    "    spec_transform=SpecTokenizer(n_peaks=60),\n",
    "    mol_transform=MolFingerprinter(),\n",
    "    candidates_pth=candidates_pth,\n",
    ")\n",
    "\n",
    "# Init data module\n",
    "data_module = MassSpecDataModule(\n",
    "    dataset=dataset,\n",
    "    split_pth=split_pth,\n",
    "    batch_size=2\n",
    ")\n",
    "\n",
    "# Init model\n",
    "model = DeepSetsRetrieval()\n",
    "# model = RandomRetrieval()\n",
    "\n",
    "# Init logger\n",
    "# You may need to run wandb init first to use the wandb logger\n",
    "# Alternatively set logger = None in Trainer below not to use wandb\n",
    "project = \"MassSpecGymRetrieval\"\n",
    "name = \"DeepSets\"\n",
    "logger = pl.loggers.WandbLogger(\n",
    "    project=project,\n",
    "    name=name,\n",
    "    tags=[],\n",
    "    log_model=False,\n",
    ")\n",
    "\n",
    "# Init trainer\n",
    "trainer = Trainer(\n",
    "    accelerator=\"cpu\", max_epochs=50, logger=logger, log_every_n_steps=1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fingerpint FFN model on the fingerprint retrieval task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anton/dev/ms/MassSpecGym/massspecgym/data/datasets.py:46: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.metadata = pd.read_csv(self.pth, sep=\"\\t\")\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/anton/miniconda3/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "source": [
    "fp_size = 4096\n",
    "\n",
    "# Load dataset\n",
    "dataset = RetrievalDataset(\n",
    "    pth=mgf_pth,\n",
    "    spec_transform=SpecBinner(),\n",
    "    mol_transform=MolFingerprinter(fp_size=fp_size),\n",
    "    candidates_pth=candidates_pth,\n",
    ")\n",
    "\n",
    "# Init data module\n",
    "data_module = MassSpecDataModule(\n",
    "    dataset=dataset,\n",
    "    split_pth=split_pth,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "# Init model\n",
    "model = FingerprintFFNRetrieval(in_channels=1000, out_channels=fp_size)\n",
    "\n",
    "# Init logger\n",
    "# You may need to run wandb init first to use the wandb logger\n",
    "# Alternatively set logger = None in Trainer below not to use wandb\n",
    "project = \"MassSpecGymRetrieval\"\n",
    "name = \"DeepSets\"\n",
    "logger = pl.loggers.WandbLogger(\n",
    "    project=project,\n",
    "    name=name,\n",
    "    tags=[],\n",
    "    log_model=False,\n",
    ")\n",
    "\n",
    "# Init trainer\n",
    "trainer = Trainer(\n",
    "    accelerator=\"cpu\", max_epochs=50, logger=logger, log_every_n_steps=50\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy model on the de novo generation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/anton/miniconda3/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "# Uncomment the paths to use debugging data containing only 5 spectra\n",
    "dataset = MassSpecDataset(\n",
    "    pth=mgf_pth,\n",
    "    spec_transform=SpecTokenizer(n_peaks=60),\n",
    "    mol_transform=None\n",
    ")\n",
    "\n",
    "# Init data module\n",
    "data_module = MassSpecDataModule(\n",
    "    dataset=dataset,\n",
    "    split_pth=split_pth,\n",
    "    batch_size=2\n",
    ")\n",
    "\n",
    "# Init model\n",
    "# model = RandomDeNovo()\n",
    "model = DummyDeNovo()\n",
    "\n",
    "# Init logger\n",
    "# You may need to run wandb init first to use the wandb logger\n",
    "# Alternatively set logger = None in Trainer below not to use wandb\n",
    "project = \"MassSpecGymDeNovo\"\n",
    "name = \"RandomBasline\"\n",
    "logger = pl.loggers.WandbLogger(\n",
    "    project=project,\n",
    "    name=name,\n",
    "    tags=[],\n",
    "    log_model=False,\n",
    ")\n",
    "\n",
    "# Init trainer\n",
    "trainer = Trainer(\n",
    "    accelerator=\"cpu\", max_epochs=50, logger=logger, log_every_n_steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De novo SMILES transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roman/miniconda/envs/massspecgym/lib/python3.11/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/roman/miniconda/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/roman/miniconda/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | src_encoder   | Linear           | 1.5 K \n",
      "1 | tgt_embedding | Embedding        | 2.6 M \n",
      "2 | transformer   | Transformer      | 16.8 M\n",
      "3 | tgt_decoder   | Linear           | 2.6 M \n",
      "4 | criterion     | CrossEntropyLoss | 0     \n",
      "---------------------------------------------------\n",
      "22.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "22.1 M    Total params\n",
      "88.496    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97844011e6d546ae9b4434cd3dfbcf24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roman/miniconda/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/roman/miniconda/envs/massspecgym/lib/python3.11/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "[22:53:07] Invalid InChI prefix in generating InChI Key\n",
      "[22:53:09] Invalid InChI prefix in generating InChI Key\n",
      "/Users/roman/miniconda/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275a00c7dd61422687a3e7a9db60d6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = MassSpecDataset(\n",
    "    pth=mgf_pth,\n",
    "    spec_transform=SpecTokenizer(n_peaks=60),\n",
    "    mol_transform=None\n",
    ")\n",
    "\n",
    "# Init data module\n",
    "data_module = MassSpecDataModule(\n",
    "    dataset=dataset,\n",
    "    split_pth=split_pth,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Init model\n",
    "model = SmilesTransformer(\n",
    "    input_dim=2,\n",
    "    d_model=512,\n",
    "    nhead=8,\n",
    "    num_encoder_layers=4,\n",
    "    num_decoder_layers=4,\n",
    "    dim_feedforward=512,\n",
    "    dropout=0.0,\n",
    "    smiles_tokenizer=utils.get_smiles_bpe_tokenizer(),\n",
    "    k_predictions=1,\n",
    "    pre_norm=False,\n",
    "    max_smiles_len=100\n",
    ")\n",
    "\n",
    "# Init trainer\n",
    "project = \"MassSpecGymDeNovo\"\n",
    "name = \"SmilesTransformer_debug_overfitting\"\n",
    "logger = pl.loggers.WandbLogger(\n",
    "    project=project,\n",
    "    name=name,\n",
    "    tags=[],\n",
    "    log_model=False,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    accelerator=\"cpu\", max_epochs=1000, logger=logger, log_every_n_steps=1, check_val_every_n_epoch=4000\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COc1ncc2cc(C(=O)Nc3c(Cl)ccc(C(=O)NCc4cc(Cl)ccc4)c3)c(=O)[nH]c2n1', 'CNC(=O)O[C@H]1COc2c(cc(N3CCN(C4COC4)CC3)cc2)[C@@H]1NC(=O)c1ccc(F)cc1', 'C/C1=C/CC[C@@]2(C)O[C@@H]2[C@H]2OC(=O)[C@H](CN(C)C)[C@@H]2CC1']\n",
      "[['COc1ncc2cc(C(=O)Nc3c(Cl)ccc(C(=O)NCc4cc(Cl)ccc4)c3)c(=O)[nH]c2n1'], ['CNC(=O)O[C@H]1COc2c(cc(N3CCN(C4COC4)CC3)cc2)[C@@H]1NC(=O)c1ccc(F)cc1'], ['C/C1=C/CC[C@@]2(C)O[C@@H]2[C@H]2OC(=O)[C@H](CN(C)C)[C@@H]2CC1']]\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    batch = next(iter(data_module.train_dataloader()))\n",
    "    print(batch['mol'])\n",
    "    print(model.decode_smiles(batch['spec'].float()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-bushuiev\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240601_152602-qckqmb1j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/anton-bushuiev/MassSpecGymDeNovo/runs/qckqmb1j' target=\"_blank\">RandomBasline</a></strong> to <a href='https://wandb.ai/anton-bushuiev/MassSpecGymDeNovo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/anton-bushuiev/MassSpecGymDeNovo' target=\"_blank\">https://wandb.ai/anton-bushuiev/MassSpecGymDeNovo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/anton-bushuiev/MassSpecGymDeNovo/runs/qckqmb1j' target=\"_blank\">https://wandb.ai/anton-bushuiev/MassSpecGymDeNovo/runs/qckqmb1j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anton/miniconda3/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd1eb615b304a448e57fdc16b040435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anton/miniconda3/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py:181: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name                        | Type       | Params\n",
      "-----------------------------------------------------------\n",
      "0 | val_top_1_min_mces_dist     | MeanMetric | 0     \n",
      "1 | val_top_1_max_tanimoto_sim  | MeanMetric | 0     \n",
      "2 | val_top_1_accuracy          | MeanMetric | 0     \n",
      "3 | val_top_10_min_mces_dist    | MeanMetric | 0     \n",
      "4 | val_top_10_max_tanimoto_sim | MeanMetric | 0     \n",
      "5 | val_top_10_accuracy         | MeanMetric | 0     \n",
      "-----------------------------------------------------------\n",
      "0         Trainable params\n",
      "0         Non-trainable params\n",
      "0         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      Validate metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "    val_top_10_accuracy                0.0\n",
      "val_top_10_max_tanimoto_sim    0.1066666692495346\n",
      " val_top_10_min_mces_dist             26.0\n",
      "    val_top_1_accuracy                 0.0\n",
      "val_top_1_max_tanimoto_sim     0.10526315867900848\n",
      "  val_top_1_min_mces_dist             29.5\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09216feeddb4d43aeb6df155667e1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anton/miniconda3/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/anton/miniconda3/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4c615fd9ad451287bf8de610625120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a264b1306342368c83fa4c56f7d212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547ffee2b4e14155b87af5f9eedf631e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da98fa0a170b4fa6a03fc3522ce222db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1eff984e534b8794e6051ac6aeac7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3d95b4560c4991885a7af21fc9921c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c29745e8c094bf8a9e4179983114df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bfd1f7c7d244a2a0f58d382c8a0bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a90361785946108b0a28bda9458f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c431427906ea44fa8a784863c81f7c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd724eb4e2d4e7dad1bbfb3b9a7553e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eaf65b3264b41f4acee4551a3ccc602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cde4ede742a42e196166f47fc38d357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8cf791da2f4175acae7110cd0d6862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2deccdcbb5e24670b44edf7835c17b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0efaf7b3fc741b0aeed88986df48d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7caaf450d30945a6b68a1d36e60b8bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4eae5d93534507ba1ebb20a79060ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc7e892dfaa4d6386b6163acb3fd407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3947955004314ffa98876d63b235b893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b254fd62d4e240f7826da683323dce2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3a056561164a9db1caee3a89ac5b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84cb35394b3b4ab8a596441558eac75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583064353fc844cc992194d6c5534afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed532bd217fb470a90368270825eed22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822fd68f184143d3919ac7482dbbb542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f9749291ef430fb0c5e943e61c3109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf5f795ce4940b99d6971c0177dac87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdcb8a9210b44f47b672fa4ce5904485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c740c2b2151c4427bd6ec68c3cd2d881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1107cd640d77455ebf7a63a698223ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06319c8a97154e779332c679c236e147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158cfda322eb40c8a616b40ce1d522a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a234edba771a4207a082206a1d72f231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anton/miniconda3/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "# Validate before training\n",
    "data_module.prepare_data()  # Explicit call needed for validate before fit\n",
    "data_module.setup()  # Explicit call needed for validate before fit\n",
    "trainer.validate(model, datamodule=data_module)\n",
    "\n",
    "# Train\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anton/miniconda3/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a559f4e790604d308db4dfd3cb827d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "No registered converter was able to produce a C++ rvalue of type std::__1::basic_string<wchar_t, std::__1::char_traits<wchar_t>, std::__1::allocator<wchar_t>> from this Python object of type NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtest(model, datamodule\u001b[39m=\u001b[39;49mdata_module)\n",
      "File \u001b[0;32m~/miniconda3/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:754\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[1;32m    753\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtesting \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 754\u001b[0m \u001b[39mreturn\u001b[39;00m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    755\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_test_impl, model, dataloaders, ckpt_path, verbose, datamodule\n\u001b[1;32m    756\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:794\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    791\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    792\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn, ckpt_path, model_provided\u001b[39m=\u001b[39mmodel_provided, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    793\u001b[0m )\n\u001b[0;32m--> 794\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    795\u001b[0m \u001b[39m# remove the tensors from the test results\u001b[39;00m\n\u001b[1;32m    796\u001b[0m results \u001b[39m=\u001b[39m convert_tensors_to_scalars(results)\n",
      "File \u001b[0;32m~/miniconda3/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:987\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    984\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 987\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    989\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1026\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mzero_grad(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mzero_grad_kwargs)\n\u001b[1;32m   1025\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluating:\n\u001b[0;32m-> 1026\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1027\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1028\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/miniconda3/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mis_last_batch \u001b[39m=\u001b[39m data_fetcher\u001b[39m.\u001b[39mdone\n\u001b[1;32m    134\u001b[0m     \u001b[39m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n\u001b[1;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[39m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py:411\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    409\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mon_test_batch_end\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mon_validation_batch_end\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(trainer, hook_name, output, \u001b[39m*\u001b[39mhook_kwargs\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m--> 411\u001b[0m call\u001b[39m.\u001b[39;49m_call_lightning_module_hook(trainer, hook_name, output, \u001b[39m*\u001b[39;49mhook_kwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    413\u001b[0m trainer\u001b[39m.\u001b[39m_logger_connector\u001b[39m.\u001b[39mon_batch_end()\n\u001b[1;32m    415\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m~/miniconda3/envs/massspecgym/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:157\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[1;32m    156\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 157\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    159\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    160\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/dev/ms/MassSpecGym/massspecgym/models/base.py:58\u001b[0m, in \u001b[0;36mMassSpecGymModel.on_test_batch_end\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_test_batch_end\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mon_batch_end(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, metric_pref\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtest_\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/dev/ms/MassSpecGym/massspecgym/models/de_novo/base.py:47\u001b[0m, in \u001b[0;36mDeNovoMassSpecGymModel.on_batch_end\u001b[0;34m(self, outputs, batch, batch_idx, metric_pref)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_batch_end\u001b[39m(\n\u001b[1;32m     41\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     42\u001b[0m     outputs: T\u001b[39m.\u001b[39mAny,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     metric_pref: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     46\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate_de_novo_step(\n\u001b[1;32m     48\u001b[0m         outputs[\u001b[39m\"\u001b[39;49m\u001b[39mmols_pred\u001b[39;49m\u001b[39m\"\u001b[39;49m],  \u001b[39m# (bs, k) list of generated rdkit molecules or SMILES strings\u001b[39;49;00m\n\u001b[1;32m     49\u001b[0m         batch[\u001b[39m\"\u001b[39;49m\u001b[39mmol\u001b[39;49m\u001b[39m\"\u001b[39;49m],  \u001b[39m# (bs) list of ground truth SMILES strings\u001b[39;49;00m\n\u001b[1;32m     50\u001b[0m         metric_pref\u001b[39m=\u001b[39;49mmetric_pref\n\u001b[1;32m     51\u001b[0m     )\n",
      "File \u001b[0;32m~/dev/ms/MassSpecGym/massspecgym/models/de_novo/base.py:97\u001b[0m, in \u001b[0;36mDeNovoMassSpecGymModel.evaluate_de_novo_step\u001b[0;34m(self, mols_pred, mol_true, metric_pref)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39m# Iterate over batch\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mfor\u001b[39;00m preds, true \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(smiles_pred_top_k, smile_true):\n\u001b[1;32m     96\u001b[0m     \u001b[39m# Iterate over top-k predicted molecule samples\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m     dists \u001b[39m=\u001b[39m [MCES(s1\u001b[39m=\u001b[39;49mtrue, s2\u001b[39m=\u001b[39;49mpred, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmyopic_mces_kwargs)[\u001b[39m1\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m pred \u001b[39min\u001b[39;49;00m preds]\n\u001b[1;32m     98\u001b[0m     min_mces_dists\u001b[39m.\u001b[39mappend(\u001b[39mmin\u001b[39m(dists))\n\u001b[1;32m     99\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_metric(\n\u001b[1;32m    100\u001b[0m     metric_pref \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtop_\u001b[39m\u001b[39m{\u001b[39;00mtop_k\u001b[39m}\u001b[39;00m\u001b[39m_min_mces_dist\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    101\u001b[0m     MeanMetric,\n\u001b[1;32m    102\u001b[0m     (min_mces_dists,),\n\u001b[1;32m    103\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(min_mces_dists),\n\u001b[1;32m    104\u001b[0m )\n",
      "File \u001b[0;32m~/dev/ms/MassSpecGym/massspecgym/models/de_novo/base.py:97\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39m# Iterate over batch\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mfor\u001b[39;00m preds, true \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(smiles_pred_top_k, smile_true):\n\u001b[1;32m     96\u001b[0m     \u001b[39m# Iterate over top-k predicted molecule samples\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m     dists \u001b[39m=\u001b[39m [MCES(s1\u001b[39m=\u001b[39;49mtrue, s2\u001b[39m=\u001b[39;49mpred, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmyopic_mces_kwargs)[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m pred \u001b[39min\u001b[39;00m preds]\n\u001b[1;32m     98\u001b[0m     min_mces_dists\u001b[39m.\u001b[39mappend(\u001b[39mmin\u001b[39m(dists))\n\u001b[1;32m     99\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_metric(\n\u001b[1;32m    100\u001b[0m     metric_pref \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtop_\u001b[39m\u001b[39m{\u001b[39;00mtop_k\u001b[39m}\u001b[39;00m\u001b[39m_min_mces_dist\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    101\u001b[0m     MeanMetric,\n\u001b[1;32m    102\u001b[0m     (min_mces_dists,),\n\u001b[1;32m    103\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(min_mces_dists),\n\u001b[1;32m    104\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/massspecgym/lib/python3.11/site-packages/myopic_mces/myopic_mces.py:58\u001b[0m, in \u001b[0;36mMCES\u001b[0;34m(ind, s1, s2, threshold, solver, solver_options, no_ilp_threshold, always_stronger_bound)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m# construct graph for both smiles.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m G1 \u001b[39m=\u001b[39m construct_graph(s1)\n\u001b[0;32m---> 58\u001b[0m G2 \u001b[39m=\u001b[39m construct_graph(s2)\n\u001b[1;32m     59\u001b[0m \u001b[39m# filter out if distance is above the threshold\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m threshold \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/massspecgym/lib/python3.11/site-packages/myopic_mces/graph.py:27\u001b[0m, in \u001b[0;36mconstruct_graph\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" \u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mConverts a SMILE into a graph\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m    The atom types are represented as atom attributes of the nodes.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39m#read the smile\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m m \u001b[39m=\u001b[39m Chem\u001b[39m.\u001b[39;49mMolFromSmiles(s)\n\u001b[1;32m     28\u001b[0m \u001b[39m# convert the molecule into a graph\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m# The bond and atom types are converted to node/edge attributes\u001b[39;00m\n\u001b[1;32m     30\u001b[0m G\u001b[39m=\u001b[39mnx\u001b[39m.\u001b[39mGraph()\n",
      "\u001b[0;31mTypeError\u001b[0m: No registered converter was able to produce a C++ rvalue of type std::__1::basic_string<wchar_t, std::__1::char_traits<wchar_t>, std::__1::allocator<wchar_t>> from this Python object of type NoneType"
     ]
    }
   ],
   "source": [
    "trainer.test(model, datamodule=data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "massspecgym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
